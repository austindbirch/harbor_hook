# Default values for harborhook.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: nginx
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: ""

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

podAnnotations: {}

podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

service:
  type: ClusterIP
  port: 80

ingress:
  enabled: false
  className: ""
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80

nodeSelector: {}

tolerations: []

affinity: {}

# Global configuration for Harborhook services
config:
  db:
    user: "postgres"
    pass: "postgres" # In production, we should use a secret
    host: "postgres" # This will be the service name of the postgres chart
    port: "5432"
    name: "harborhook"
    # The password will be handled via secrets
  nsq:
    nsqdTcpAddr: "harborhook-nsqd:4150"
    nsqLookupHttpAddr: "harborhook-nsqlookupd:4161"
    deliveriesTopic: "deliveries"
    dlqTopic: "dlq"
    workerChannel: "workers"
  webhook:
    signatureHeader: "X-Harborhook-Signature"
    timestampHeader: "X-Harborhook-Timestamp"
  otel:
    endpoint: "http://harborhook-tempo:4318"

# Ingest service configuration
ingest:
  replicaCount: 1
  image:
    repository: ghcr.io/austindbirch/harbor_hook/ingest
    pullPolicy: IfNotPresent
    tag: "latest"
  service:
    httpPort: 8080
    grpcPort: 50051
  # The name of the secret containing the TLS certificates
  certsSecretName: harborhook-certs

# Worker service configuration
worker:
  replicaCount: 3
  image:
    repository: ghcr.io/austindbirch/harbor_hook/worker
    pullPolicy: IfNotPresent
    tag: "latest"
  service:
    httpPort: 8083 # Internal port for metrics/health
  certsSecretName: harborhook-certs
  # Worker specific settings
  maxAttempts: 5
  backoffSchedule: "1s,5s,10s,30s,1m"
  backoffJitterPct: 0.1
  concurrency: 100
  httpClientTimeout: "30s"

# JWKS Server configuration
jwksServer:
  replicaCount: 1
  image:
    repository: ghcr.io/austindbirch/harbor_hook/jwks-server
    pullPolicy: IfNotPresent
    tag: "latest"
  service:
    httpPort: 8082

# Fake Receiver configuration
fakeReceiver:
  replicaCount: 1
  image:
    repository: ghcr.io/austindbirch/harbor_hook/fake-receiver
    pullPolicy: IfNotPresent
    tag: "latest"
  service:
    httpPort: 8081
  # -- Configuration for the fake receiver's behavior
  config:
    failFirstN: 0
    endpointSecret: "demo_secret"
    signingLeewaySeconds: 300
    responseDelayMs: 0

# Configuration for the postgresql subchart
postgres:
  image:
    # Use latest tag for the hardened Bitnami PostgreSQL image
    tag: "latest"
  auth:
    database: "harborhook"
    username: "postgres"
    # In a production environment, this should be sourced from a secret.
    password: "postgres"
  primary:
    persistence:
      enabled: true
      size: 1Gi
    initdb:
      # Database initialization scripts - executed in alphabetical order
      scripts:
        01_init.sql: |
          CREATE SCHEMA IF NOT EXISTS harborhook;
          CREATE TABLE IF NOT EXISTS harborhook.tenants (
              id   TEXT PRIMARY KEY,
              name TEXT NOT NULL,
              created_at TIMESTAMPTZ NOT NULL DEFAULT now()
          );
          INSERT INTO harborhook.tenants (id, name) VALUES ('tn_demo', 'Demo Tenant')
          ON CONFLICT DO NOTHING;
        02_create_schema_phase1.sql: |
          CREATE EXTENSION IF NOT EXISTS pgcrypto;
          CREATE TABLE IF NOT EXISTS harborhook.endpoints (
              id           UUID PRIMARY KEY DEFAULT gen_random_uuid(),
              tenant_id    TEXT NOT NULL,
              url          TEXT NOT NULL,
              secret       TEXT,
              headers      JSONB NOT NULL DEFAULT '{}'::jsonb,
              rate_per_sec INT NOT NULL DEFAULT 0,
              created_at   TIMESTAMPTZ NOT NULL DEFAULT now()
          );
          CREATE TABLE IF NOT EXISTS harborhook.subscriptions (
              id           UUID PRIMARY KEY DEFAULT gen_random_uuid(),
              tenant_id    TEXT NOT NULL,
              event_type   TEXT NOT NULL,
              endpoint_id  UUID NOT NULL REFERENCES harborhook.endpoints(id) ON DELETE CASCADE,
              created_at   TIMESTAMPTZ NOT NULL DEFAULT now()
          );
          CREATE TABLE IF NOT EXISTS harborhook.events (
              id            UUID PRIMARY KEY DEFAULT gen_random_uuid(),
              tenant_id     TEXT NOT NULL,
              event_type    TEXT NOT NULL,
              payload       JSONB NOT NULL,
              occurred_at   TIMESTAMPTZ NOT NULL DEFAULT now(),
              created_at    TIMESTAMPTZ NOT NULL DEFAULT now()
          );
          DO $$
          BEGIN
              IF NOT EXISTS (SELECT 1 FROM pg_type WHERE typname = 'delivery_status') THEN
                  CREATE TYPE delivery_status AS ENUM ('pending', 'ok', 'failed');
              END IF;
          END$$;
          CREATE TABLE IF NOT EXISTS harborhook.deliveries (
              id          UUID PRIMARY KEY DEFAULT gen_random_uuid(),
              event_id    UUID NOT NULL REFERENCES harborhook.events(id) ON DELETE CASCADE,
              endpoint_id UUID NOT NULL REFERENCES harborhook.endpoints(id) ON DELETE CASCADE,
              status      delivery_status NOT NULL DEFAULT 'pending',
              attempt     INT NOT NULL DEFAULT 0,
              http_status INT,
              latency_ms  INT,
              last_error  TEXT,
              next_try_at TIMESTAMPTZ,
              created_at  TIMESTAMPTZ NOT NULL DEFAULT now(),
              updated_at  TIMESTAMPTZ NOT NULL DEFAULT now()
          );
          CREATE INDEX IF NOT EXISTS idx_subs_tenant_event ON harborhook.subscriptions(tenant_id, event_type);
          CREATE INDEX IF NOT EXISTS idx_events_tenant_created ON harborhook.events(tenant_id, created_at DESC);
          CREATE INDEX IF NOT EXISTS idx_deliveries_endpoint_status ON harborhook.deliveries(endpoint_id, status);
        03_phase2.sql: |
          ALTER TYPE delivery_status ADD VALUE IF NOT EXISTS 'queued';
          ALTER TYPE delivery_status ADD VALUE IF NOT EXISTS 'inflight';
          ALTER TYPE delivery_status ADD VALUE IF NOT EXISTS 'delivered';
          ALTER TYPE delivery_status ADD VALUE IF NOT EXISTS 'dead';
          UPDATE harborhook.deliveries SET status = 'queued' WHERE status = 'pending';
          UPDATE harborhook.deliveries SET status = 'delivered' WHERE status = 'ok';
          ALTER TABLE harborhook.deliveries ALTER COLUMN status SET DEFAULT 'queued';
          ALTER TABLE harborhook.events ADD COLUMN IF NOT EXISTS idempotency_key TEXT;
          DO $$
          BEGIN
              IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname = 'uq_events_tenant_idem') THEN
                  ALTER TABLE harborhook.events ADD CONSTRAINT uq_events_tenant_idem UNIQUE (tenant_id, idempotency_key);
              END IF;
          END$$;
          CREATE TABLE IF NOT EXISTS harborhook.dlq (
            id           UUID PRIMARY KEY DEFAULT gen_random_uuid(),
            delivery_id  UUID NOT NULL REFERENCES harborhook.deliveries(id) ON DELETE CASCADE,
            reason       TEXT NOT NULL,
            created_at   TIMESTAMPTZ NOT NULL DEFAULT now()
          );
        04_phase3.sql: |
          BEGIN;
          ALTER TABLE harborhook.deliveries ADD COLUMN IF NOT EXISTS replay_of UUID REFERENCES harborhook.deliveries(id) ON DELETE SET NULL;
          ALTER TABLE harborhook.deliveries ADD COLUMN IF NOT EXISTS replay_reason TEXT NULL;
          ALTER TABLE harborhook.deliveries
              ADD COLUMN IF NOT EXISTS enqueued_at   TIMESTAMPTZ DEFAULT now(),
              ADD COLUMN IF NOT EXISTS dequeued_at   TIMESTAMPTZ,
              ADD COLUMN IF NOT EXISTS sent_at       TIMESTAMPTZ,
              ADD COLUMN IF NOT EXISTS delivered_at  TIMESTAMPTZ,
              ADD COLUMN IF NOT EXISTS failed_at     TIMESTAMPTZ,
              ADD COLUMN IF NOT EXISTS dlq_at        TIMESTAMPTZ,
              ADD COLUMN IF NOT EXISTS error_reason  TEXT;
          CREATE INDEX IF NOT EXISTS idx_deliveries_event_id ON harborhook.deliveries(event_id);
          CREATE INDEX IF NOT EXISTS idx_deliveries_endpoint_time ON harborhook.deliveries(endpoint_id, enqueued_at);
          CREATE INDEX IF NOT EXISTS idx_deliveries_replay_of ON harborhook.deliveries(replay_of);
          CREATE UNIQUE INDEX IF NOT EXISTS uq_single_pending_replay ON harborhook.deliveries(replay_of) WHERE status IN ('queued', 'inflight');
          CREATE OR REPLACE FUNCTION update_delivery_timestamps() RETURNS TRIGGER AS $$
          BEGIN
              CASE NEW.status
                  WHEN 'queued' THEN
                      IF OLD.status IS DISTINCT FROM NEW.status AND NEW.enqueued_at IS NULL THEN
                          NEW.enqueued_at = now();
                      END IF;
                  WHEN 'inflight' THEN
                      IF OLD.status IS DISTINCT FROM NEW.status THEN
                          NEW.dequeued_at = now();
                      END IF;
                  WHEN 'delivered' THEN
                      IF OLD.status IS DISTINCT FROM NEW.status THEN
                          NEW.delivered_at = now();
                      END IF;
                  WHEN 'failed' THEN
                      IF OLD.status IS DISTINCT FROM NEW.status THEN
                          NEW.failed_at = now();
                      END IF;
                  WHEN 'dead' THEN
                      IF OLD.status IS DISTINCT FROM NEW.status THEN
                          NEW.dlq_at = now();
                      END IF;
              END CASE;
              NEW.updated_at = now();
              RETURN NEW;
          END;
          $$ LANGUAGE plpgsql;
          DROP TRIGGER IF EXISTS delivery_timestamps_trigger ON harborhook.deliveries;
          CREATE TRIGGER delivery_timestamps_trigger BEFORE UPDATE ON harborhook.deliveries FOR EACH ROW EXECUTE FUNCTION update_delivery_timestamps();
          CREATE OR REPLACE FUNCTION set_initial_timestamps() RETURNS TRIGGER AS $$
          BEGIN
              IF NEW.status = 'queued' AND NEW.enqueued_at IS NULL THEN
                  NEW.enqueued_at = now();
              END IF;
              NEW.created_at = COALESCE(NEW.created_at, now());
              NEW.updated_at = now();
              RETURN NEW;
          END;
          $$ LANGUAGE plpgsql;
          DROP TRIGGER IF EXISTS delivery_insert_timestamps_trigger ON harborhook.deliveries;
          CREATE TRIGGER delivery_insert_timestamps_trigger BEFORE INSERT ON harborhook.deliveries FOR EACH ROW EXECUTE FUNCTION set_initial_timestamps();
          COMMIT;

# Configuration for the nsq subchart
nsq:
  nsqd:
    enabled: true
    replicaCount: 1
    persistence:
      enabled: false
  nsqlookupd:
    enabled: true
    replicaCount: 1
    persistence:
      enabled: false
  nsqadmin:
    enabled: true
    replicaCount: 1

# Envoy gateway configuration
envoy:
  replicaCount: 1
  image:
    repository: envoyproxy/envoy
    pullPolicy: IfNotPresent
    tag: "v1.23.1" # Use a specific, stable version
  service:
    type: LoadBalancer
    httpPort: 8443
  certsSecretName: harborhook-certs

# Nsq-monitor configuration
nsqMonitor:
  replicaCount: 1
  image:
    repository: ghcr.io/austindbirch/harbor_hook/nsq-monitor
    pullPolicy: IfNotPresent
    tag: "latest"
  service:
    httpPort: 8084
  env:
    NSQD_HOST: "nsqd:4151"
    PORT: 8084
    POLL_INTERVAL_SECONDS: 15
  podAnnotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: 8084
    prometheus.io/path: "/metrics"

# Observability stack configuration
observability:
  # -- Enable/disable the entire observability stack
  enabled: true

  # Prometheus configuration (using prometheus-community chart)
  prometheus:
    enabled: true
    server:
      service:
        type: ClusterIP
        servicePort: 9090
      retention: "15d"
      extraConfigmapMounts:
        - name: alert-rules
          mountPath: /etc/config/alert-rules.yaml
          subPath: alert-rules.yaml
          configMap: '{{ include "harborhook.fullname" . }}-alert-rules'
          readOnly: true
    alertmanager:
      enabled: true
      service:
        type: ClusterIP
        servicePort: 9093
    configmapReload:
      prometheus:
        enabled: true
      alertmanager:
        enabled: true
    serverFiles:
      alerting_rules.yml: {}
      recording_rules.yml: {}
      prometheus.yml:
        rule_files:
          - /etc/config/alert-rules.yaml
        scrape_configs:
          - job_name: prometheus
            static_configs:
              - targets:
                  - localhost:9090
          - job_name: ingest
            kubernetes_sd_configs:
              - role: pod
                namespaces:
                  names:
                    - default
            relabel_configs:
              - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_component]
                action: keep
                regex: ingest
              - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
                action: keep
                regex: true
              - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port]
                action: replace
                target_label: __address__
                regex: (.+)
                replacement: __meta_kubernetes_pod_ip:$1
          - job_name: worker
            kubernetes_sd_configs:
              - role: pod
                namespaces:
                  names:
                    - default
            relabel_configs:
              - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_component]
                action: keep
                regex: worker
              - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
                action: keep
                regex: true
              - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port]
                action: replace
                target_label: __address__
                regex: (.+)
                replacement: __meta_kubernetes_pod_ip:$1
          - job_name: nsq-monitor
            kubernetes_sd_configs:
              - role: pod
                namespaces:
                  names:
                    - default
            relabel_configs:
              - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_component]
                action: keep
                regex: nsq-monitor
              - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
                action: keep
                regex: true
              - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port]
                action: replace
                target_label: __address__
                regex: (.+)
                replacement: __meta_kubernetes_pod_ip:$1
    alertmanagerFiles:
      alertmanager.yml:
        global: {}
        route:
          group_by: ['alertname', 'cluster', 'service']
          group_wait: 10s
          group_interval: 10s
          repeat_interval: 12h
          receiver: 'null'
        receivers:
          - name: 'null'

  # Grafana configuration (using grafana community chart)
  grafana:
    enabled: true
    service:
      type: ClusterIP
      port: 80
    adminUser: admin
    adminPassword: admin
    datasources:
      datasources.yaml:
        apiVersion: 1
        datasources:
          - name: Prometheus
            type: prometheus
            access: proxy
            url: http://{{ .Release.Name }}-prometheus-server:9090
            isDefault: true
            editable: true
          - name: Tempo
            type: tempo
            access: proxy
            url: http://{{ .Release.Name }}-tempo:3200
            editable: true
            jsonData:
              httpMethod: GET
              tracesToMetrics:
                datasourceUid: 'prometheus'
                spanStartTimeShift: '-1h'
                spanEndTimeShift: '1h'
              serviceMap:
                datasourceUid: 'prometheus'
              nodeGraph:
                enabled: true
              search:
                hide: false
              spanBar:
                type: 'Tag'
                tag: 'http.path'

  # Loki configuration (using SingleBinary mode for filesystem storage)
  # Note: Disabled temporarily - needs proper object storage configuration
  loki:
    enabled: false
    deploymentMode: SingleBinary
    loki:
      auth_enabled: false
      commonConfig:
        replication_factor: 1
      storage:
        type: 'filesystem'
        bucketNames:
          chunks: chunks
          ruler: ruler
          admin: admin
      schemaConfig:
        configs:
          - from: "2025-09-01"
            store: tsdb
            object_store: filesystem
            schema: v13
            index:
              prefix: index_
              period: 24h
    singleBinary:
      replicas: 1
    # Explicitly disable other components for SingleBinary mode
    write:
      replicas: 0
    read:
      replicas: 0
    backend:
      replicas: 0

  # Tempo configuration
  tempo:
    enabled: true
    service:
      type: ClusterIP
      port: 3200
    tempo:
      receiversConfig:
        otlp:
          protocols:
            grpc:
              endpoint: 0.0.0.0:4317
            http:
              endpoint: 0.0.0.0:4318
      metricsGenerator:
        enabled: true
        remoteWriteUrl: "http://{{ .Release.Name }}-prometheus-server:9090/api/v1/write"
      storage:
        trace:
          backend: local
          local:
            path: /var/tempo/traces

  # Promtail configuration
  # Note: Disabled temporarily since Loki is disabled
  promtail:
    enabled: false
    config:
      clients:
        - url: http://{{ .Release.Name }}-loki:3100/loki/api/v1/push
      positions:
        filename: /tmp/positions.yaml
      scrapeConfigs:
        - job_name: kubernetes-pods
          kubernetes_sd_configs:
            - role: pod
          relabel_configs:
            - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_component]
              target_label: component
            - source_labels: [__meta_kubernetes_pod_name]
              target_label: pod
            - source_labels: [__meta_kubernetes_namespace]
              target_label: namespace
          pipeline_stages:
            - json:
                expressions:
                  timestamp: time
                  level: level
                  message: msg
                  trace_id: trace_id
                  tenant_id: tenant_id
                  event_id: event_id
                  delivery_id: delivery_id
                  endpoint_id: endpoint_id
            - timestamp:
                source: timestamp
                format: RFC3339Nano
            - labels:
                level:
                trace_id:
                tenant_id:
